{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Simple Neural Network Demo**\n",
    "\n",
    "This is a very simple neural network with 1 hidden layer and 2 hidden units using numpy.\n",
    "\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we are going to create a dataset with 2 features, which is the hight, wight of a person and the output is the person's gender.\n",
    "\n",
    "We can randomly create this dataset by using np.random package. To simplify, the output label '0' denots female and '1' denotes male."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data\n",
    "np.random.seed(0) # seed a random seed to make the data reproducible\n",
    "height = np.random.randint(150, 200, 100)\n",
    "weight = np.random.randint(50, 100, 100)\n",
    "gender = np.random.randint(0, 2, 100)\n",
    "\n",
    "# Stack the data to create out training data\n",
    "X = np.column_stack((height, weight))\n",
    "y = gender.reshape(-1, 1)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can plot the data to see how it looks\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(X[:, 0], X[:, 1], y, c=y, cmap='viridis')\n",
    "ax.set_xlabel('Height')\n",
    "ax.set_ylabel('Weight')\n",
    "ax.set_zlabel('Gender')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Steps to build a neural network**\n",
    "\n",
    "1. Define our objective\n",
    "2. Forward Propagate\n",
    "3. Compute the loss\n",
    "4. Update the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"SimpleNN.png\" width=\"800\" height=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Sigmoid Function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the weights\n",
    "W1 = 0.01 * np.random.randn(2, 2)\n",
    "W2 = 0.01 * np.random.randn(2, 1)\n",
    "\n",
    "# Forward pass\n",
    "def forward(X, W1, W2):\n",
    "    hidden = sigmoid(np.dot(X, W1))\n",
    "    output = sigmoid(np.dot(hidden, W2))\n",
    "    output = np.round(output)\n",
    "    return hidden, output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function of a binary classification problem:\n",
    "\n",
    "$$\n",
    "L(y, \\hat{y}) = -\\sum_{i} y \\log \\hat{y}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The partial deravative of $w$\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w} = \\frac{\\partial L}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial y} \\cdot \\frac{\\partial y}{\\partial w}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\hat{y}} = -y \\cdot \\frac{1}{\\hat{y}}\n",
    "$$\n",
    "$$\n",
    "\\hat {y} = sigmoid(y)\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial \\hat{y}}{\\partial y} = \\hat{y} \\cdot (1-\\hat{y})\n",
    "$$\n",
    "$$\n",
    "y = w3 \\cdot h1 + w4 \\cdot h2\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial y}{\\partial w3} = h1\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial y}{\\partial w4} = h2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can compute the gradient of $W2$**\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w3} = -y(1-\\hat{y}) \\cdot h1\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w4} = -y(1-\\hat{y}) \\cdot h2\n",
    "$$\n",
    "**We can rewrite the 2 formula into**\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W2} = -y(1-\\hat{y}) \\cdot Hidden\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can furthure compute the gradient of $w11$**\n",
    "$$\n",
    "y = w3 * h1 + w4 * h2\n",
    "$$\n",
    "$$\n",
    "h1 = sigmoid(x1 * w11+ x2 * w21)\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w11} = \\frac{\\partial L}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial y} \\cdot \\frac{\\partial y}{\\partial h1} \\cdot \\frac{\\partial h1}{\\partial w11}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial y}{\\partial h1} = w3\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial h1}{\\partial w11} = h1(1-h1) \\cdot x1\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w11} = -y(1-\\hat {y}) \\cdot w3 \\cdot h1(1-h1) \\cdot x1\n",
    "$$\n",
    "**Same as $w21$**\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w21} = -y(1-\\hat {y}) \\cdot w3 \\cdot h1(1-h1) \\cdot x2\n",
    "$$\n",
    "**Hence, we can rewrite W1 into**\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W1} = -y(1-\\hat {y}) \\cdot W2 \\cdot Hidden(1-Hidden) \\cdot X\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward pass of Cross Entropy Loss\n",
    "def backward(y, hidden, output, W1, W2, lr=0.01):\n",
    "    dW2 = - np.dot(hidden.T, y * (1 - output))\n",
    "    dW1 = - np.dot(X.T, np.dot(y * (1 - output), W2.T) * hidden * (1 - hidden))\n",
    "    W1 = lr * dW1\n",
    "    W2 -= lr * dW2\n",
    "    return W1, W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "for i in range(1000):\n",
    "    hidden, output = forward(X, W1, W2)\n",
    "    W1, W2 = backward(y, hidden, output, W1, W2)\n",
    "\n",
    "# Test the model\n",
    "hidden, output = forward(X, W1, W2)\n",
    "print(np.mean(output == y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
